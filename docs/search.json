[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rachid SAHLI",
    "section": "",
    "text": "Je suis √©tudiant √† l‚ÄôIUT Paris Rives de Seine en Science des donn√©es et alternant √† l‚ÄôINSEE. Au sein de la direction des statistiques d√©mographiques et sociales, mes missions portent sur la couverture de diff√©rentes bases de sondage et sur l‚Äôappariement de gros volumes de donn√©es.\nJ‚Äôaime les statistiques, le soleil ‚òÄÔ∏è, le v√©lo üö≤ , le cin√©ma üéûÔ∏è et la programmation üëæ."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "√Ä propos",
    "section": "",
    "text": "IUT de Paris - Rives de Seine (Universit√© Paris Cit√©) | Paris, France\n\n\n\nBachelor universitaire de technologie en Science des donn√©es | Sept 2022 - Juin 2025\nCours suivis : Alg√®bre, Statistique, Probabilit√©s, Programmation, Base de donn√©es, √âconomie"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "L‚Äôalgorithme des \\(k\\) plus proches voisins\n\n\n\n\n\n\nR\n\n\nMachine learning\n\n\n\nApplication sur R de l‚Äôalgorithme des \\(k\\) plus proches voisins.\n\n\n\n\n\n29 sept. 2024\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "blog/knn.html",
    "href": "blog/knn.html",
    "title": "L‚Äôalgorithme des \\(k\\) plus proches voisins",
    "section": "",
    "text": "1 Introduction\nLe but de l‚Äôapprentissage supervis√© est de pr√©voir l‚Äô√©tiquette (classification) \\(Y\\) ou la valeur de \\(Y\\) (r√©gression) associ√©e √† une nouvelle entr√©e \\(X\\), o√π il est sous-entendu que (\\(X,Y\\)) est une nouvelle r√©alisation des donn√©es, ind√©pendante de l‚Äô√©chantillon observ√©.\nL‚Äôalgorithme des \\(k\\) plus proches voisins est une m√©thode d‚Äôapprentissage supervis√©. On peut l‚Äôutiliser pour classifier quand \\(Y_i\\) est une variable qualitative, les \\(Y_i\\) sont appel√©s √©tiquettes. On peut √©galement l‚Äôutiliser pour pr√©dire si \\(Y_i \\in \\mathbb{R}\\). C‚Äôest donc une r√©gression et les \\(Y_i\\) sont appel√©s variables √† expliquer.\nRemarque : On parle d‚Äôapprentissage supervis√© car pour chaque \\(X_i\\) de l‚Äô√©chantillon d‚Äôapprentissage on dispose de \\(Y_i\\), l‚Äô√©tiquette. Au contraire, on parlera d‚Äôapprentissage non-supervis√© lorsque l‚Äô√©chantillon est simplement constitu√© des \\(X_i\\).\n\n\n2 Comment √ßa marche ?\nEn Classification, pour un nouveau \\(X\\) on classifie son √©tiquette \\(Y\\) par la m√©thode des k-plus proches voisins de la fa√ßon suivante. On d√©termine tout d‚Äôabord les \\(k\\) plus proches \\(X_i\\) de l‚Äô√©chantillon par rapport √† \\(X\\) et on attribue la modalit√© dominante parmi les k modalit√©s observ√©es (on parle de vote majoritaire).\nEn R√©gression, pour un nouveau \\(X\\) on pr√©dit la valeur \\(Y\\) par la m√©thode des k-plus proches voisins de la fa√ßon suivante. On d√©termine tout d‚Äôabord les \\(k\\) plus proches \\(X_i\\) de l‚Äô√©chantillon par rapport √† \\(X\\) et on calcule la moyenne des \\(Y_i\\).\nRemarque : Pour d√©terminer les \\(k\\) plus proches \\(X_i\\) de \\(X\\) on utilise g√©n√©ralement la distance euclidienne. Il est possible de pond√©rer diff√©rement certaines composantes de \\(X_i\\) pour lesquelles on veut attribuer plus ou moins d‚Äôimportance.\nNous allons mettre en pratique ces deux m√©thodes √† travers deux exemples."
  },
  {
    "objectID": "projets.html",
    "href": "projets.html",
    "title": "Projets",
    "section": "",
    "text": "PratiqueR\n\n\n1 min.\n\n\n\nR\n\n\nData Science\n\n\n\nD√©veloppement d‚Äôun site web interactif fournissant des ressources √©ducatives et des exercices pratiques pour faciliter l‚Äôapprentissage du langage R.\n\n\n\n23 juil. 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjets BUT SD\n\n\n1 min.\n\n\n\nScience des donn√©es\n\n\nStatistique\n\n\nR\n\n\n\nVoici une liste de mes projets r√©alis√©es durant mes 3 ann√©es √† l‚Äôinstitut universitaire de technologie de Paris Rives de Seine ! (2022 - 2025)\n\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "projets/projets_but/louvre.html",
    "href": "projets/projets_but/louvre.html",
    "title": "Nocturne au mus√©e du Louvre",
    "section": "",
    "text": "Tous les vendredis, le mus√©e du Louvre offre un moment de magie √† ses visiteurs au milieu de ses collections. Au programme de ces nocturnes hebdomadaires, de nombreuses activit√©s pour petits et grands. Le 24 novembre 2023, mes camarades de l‚ÄôIUT et moi avons pu participer √† l‚Äôune de ces soir√©es. Nous avons d√©cid√© de pr√©senter certains tableaux du c√©l√®bre mus√©e au filtre de l‚ÄôIA. Au moment o√π cette technologie prend une place active dans notre soci√©t√©, avec par exemple ChatGPT, DALL-E ou encore Mistral AI, il est int√©ressant de pouvoir approfondir l‚Äôutilisation de ces outils permettant de g√©n√©rer des √©l√©ments en lien, ici, avec l‚Äôart, par exemple. De plus, ce sujet fascinant qu‚Äôest l‚Äôintelligence artificielle est plus ou moins en lien avec notre formation en science des donn√©es. Explorer ce domaine o√π se m√™lent math√©matiques, informatique et donn√©es √©tait particuli√®rement captivant.\n\nQu‚Äôavons nous fait ?\nL‚Äôobjectif final √©tait de pouvoir le 23 novembre 2024, pr√©senter une ≈ìuvre en rapport avec l‚ÄôIA au visiteur de la nocturne. Pour cela, 2 mois, auparavant, nous avons d√©cid√© de choisir un sujet d‚Äôintelligence artificielle qui pouvait co√Øncider avec une ≈ìuvre du mus√©e. Apr√®s de longues recherches passionnantes, nous avons choisi de pr√©senter les GAN (Generative adversarial networks). C‚Äôest une classe d‚Äôalgorithmes d‚Äôapprentissage non supervis√©. Ils permettent de g√©n√©rer des images avec un fort degr√© de r√©alisme. Nous avons trouv√© la technologie et les m√©thodes tr√®s int√©ressantes, d‚Äôautant plus qu‚Äôelles aboutissent √† des applications concr√®tes, telles que la g√©n√©ration d‚Äôimages artistiques. Cependant, ces algorithmes sont utilis√©s dans bien d‚Äôautres domaines tels que la m√©decine ou encore la finance. Mais concr√®tement, comment √ßa marche ?\n\n\nQu‚Äôest-ce qu‚Äôun GAN ?\nAfin de comprendre comment il fonctionne, on peut imaginer un jeu entre deux joueurs :\n\nL‚Äôartiste (G√©n√©rateur) : L‚Äôobjectif du joueur est de cr√©er des images qui se rapprochent le plus de la r√©alit√©. Pour cela, il apprend de ses erreurs et r√©essaie en continu d‚Äôobtenir l‚Äô≈ìuvre la plus proche du r√©el.\nLe juge (Discriminateur) : L‚Äôobjectif de ce joueur est de v√©rifier si les ≈ìuvres r√©alis√©es par l‚Äôartiste peuvent para√Ætre r√©elles ou si elles sont encore trop fausses. Pour cela, il compare les ≈ìuvres de l‚Äôartiste √† des ≈ìuvres r√©elles faites par des peintres.\n\nTant que l‚Äôimage n‚Äôest pas accept√© par le juge, l‚Äôartiste continue √† produire des ≈ìuvres. Voil√†, le fonctionnement d‚Äôun GAN ou deux r√©seaux de neurones se font concurrence. De cette mani√®re, il est possible de cr√©er des images, des vid√©os ou d‚Äôautres contenues de tr√®s bonnes qualit√©s.\n\n\n\n\n\n\n\nSch√©ma GAN\n\n\n\n\nPr√©sentation au public\nNous avons d√©cid√© de pr√©senter au public le travail d‚ÄôObvious. Ce collectif de chercheurs, d‚Äôartistes travaille avec des mod√®les d‚Äôapprentissage profond pour explorer le potentiel cr√©atif de l‚Äôintelligence artificielle. Ils ont justement utilis√© des GAN pour g√©n√©rer une famille de 11 tableaux (la famille Belamy). \nUn portrait a retenu notre attention, le portrait d‚ÄôEdmond de Belamy. Ce tableau est une impression sur toile qui est rentr√©e dans l‚Äôhistoire de l‚Äôart moderne. Cela, car c‚Äôest la premi√®re ≈ìuvre d‚Äôart produite par un logiciel d‚Äôintelligence artificielle √† √™tre pr√©sent√©e dans une salle des ventes. Pour couronner le tout, il a √©t√© vendu 432 500 dollars chez Christie‚Äôs le 25 octobre 2018.  De plus, ce tableau est assez troublant. Il est tr√®s difficile √† premi√®re vue de d√©terminer qu‚Äôune machine a pu en √™tre l‚Äôauteur.   Obvious √† utiliser un GAN, en l‚Äôentra√Ænant sur 15 000 portraits classiques r√©alis√©s entre le 14e et 20e si√®cle. L‚Äôalgorithme devait donc produire un tableau en sortie qui serait tr√®s ressemblant aux portraits classiques. Nous avons d√©cid√© de comparer le portrait d‚ÄôEdmond de Belamy √† une ≈ìuvre du Louvre se trouvant dans la salle 846 de l‚Äôaile Richelieu du mus√©e. C‚Äôest une peinture datant du 17e si√®cle r√©alis√©e par Jean Bray, peintre n√©erlandais. Les tableaux ont quelques points en commun : le fond noir, un homme au centre du tableau, le col blanc avec une veste noir.\n\nPortrait de BelamyPortrait de Jean de Bray\n\n\n\n\n\n\n\n\n\nPortrait d‚ÄôEdmond de Belamy, Collectif Obvious\n\n\n\n\n\n\n\n\n\n\n\nPortrait d‚Äôhomme, 1658\n\n\n\n\n\nLes visiteurs √©taient agr√©ablement surpris par le r√©alisme du portrait d‚ÄôEdmond de Belamy, mais aussi par le prix de vente de l‚Äô≈ìuvre. Ils pensaient pouvoir reconna√Ætre la r√©alisation d‚Äôune IA."
  },
  {
    "objectID": "projets/projets_but/louvre.html#quavons-nous-fait",
    "href": "projets/projets_but/louvre.html#quavons-nous-fait",
    "title": "Nocturne au mus√©e du Louvre",
    "section": "Qu‚Äôavons nous fait ?",
    "text": "Qu‚Äôavons nous fait ?\nL‚Äôobjectif final √©tait de pouvoir le 23 novembre 2024, pr√©senter une ≈ìuvre en rapport avec l‚ÄôIA au visiteur de la nocturne. Pour cela, 2 mois, auparavant, nous avons d√©cid√© de choisir un sujet d‚Äôintelligence artificielle qui pouvait co√Øncider avec une ≈ìuvre du mus√©e. Apr√®s de longues recherches passionnantes, nous avons choisi de pr√©senter les GAN (Generative adversarial networks). C‚Äôest une classe d‚Äôalgorithmes d‚Äôapprentissage non supervis√©. Ils permettent de g√©n√©rer des images avec un fort degr√© de r√©alisme. Nous avons trouv√© la technologie et les m√©thodes tr√®s int√©ressantes, d‚Äôautant plus qu‚Äôelles aboutissent √† des applications concr√®tes, telles que la g√©n√©ration d‚Äôimages artistiques. Cependant, ces algorithmes sont utilis√©s dans bien d‚Äôautres domaines tels que la m√©decine ou encore la finance. Mais concr√®tement, comment √ßa marche ?"
  },
  {
    "objectID": "projets/projets_but/louvre.html#quest-ce-quun-gan",
    "href": "projets/projets_but/louvre.html#quest-ce-quun-gan",
    "title": "Nocturne au mus√©e du Louvre",
    "section": "Qu‚Äôest-ce qu‚Äôun GAN ?",
    "text": "Qu‚Äôest-ce qu‚Äôun GAN ?\nAfin de comprendre comment il fonctionne, on peut imaginer un jeu entre deux joueurs :\n\nL‚Äôartiste (G√©n√©rateur) : L‚Äôobjectif du joueur est de cr√©er des images qui se rapprochent le plus de la r√©alit√©. Pour cela, il apprend de ses erreurs et r√©essaie en continu d‚Äôobtenir l‚Äô≈ìuvre la plus proche du r√©el.\nLe juge (Discriminateur) : L‚Äôobjectif de ce joueur est de v√©rifier si les ≈ìuvres r√©alis√©es par l‚Äôartiste peuvent para√Ætre r√©elles ou si elles sont encore trop fausses. Pour cela, il compare les ≈ìuvres de l‚Äôartiste √† des ≈ìuvres r√©elles faites par des peintres.\n\nTant que l‚Äôimage n‚Äôest pas accept√© par le juge, l‚Äôartiste continue √† produire des ≈ìuvres. Voil√†, le fonctionnement d‚Äôun GAN ou deux r√©seaux de neurones se font concurrence. De cette mani√®re, il est possible de cr√©er des images, des vid√©os ou d‚Äôautres contenues de tr√®s bonnes qualit√©s.\n\n\n\n\n\n\n\nSch√©ma GAN"
  },
  {
    "objectID": "projets/projets_but/louvre.html#pr√©sentation-au-public",
    "href": "projets/projets_but/louvre.html#pr√©sentation-au-public",
    "title": "Nocturne au mus√©e du Louvre",
    "section": "Pr√©sentation au public",
    "text": "Pr√©sentation au public\nNous avons d√©cid√© de pr√©senter au public le travail d‚ÄôObvious. Ce collectif de chercheurs, d‚Äôartistes travaille avec des mod√®les d‚Äôapprentissage profond pour explorer le potentiel cr√©atif de l‚Äôintelligence artificielle. Ils ont justement utilis√© des GAN pour g√©n√©rer une famille de 11 tableaux (la famille Belamy). \nUn portrait a retenu notre attention, le portrait d‚ÄôEdmond de Belamy. Ce tableau est une impression sur toile qui est rentr√©e dans l‚Äôhistoire de l‚Äôart moderne. Cela, car c‚Äôest la premi√®re ≈ìuvre d‚Äôart produite par un logiciel d‚Äôintelligence artificielle √† √™tre pr√©sent√©e dans une salle des ventes. Pour couronner le tout, il a √©t√© vendu 432 500 dollars chez Christie‚Äôs le 25 octobre 2018.  De plus, ce tableau est assez troublant. Il est tr√®s difficile √† premi√®re vue de d√©terminer qu‚Äôune machine a pu en √™tre l‚Äôauteur.   Obvious √† utiliser un GAN, en l‚Äôentra√Ænant sur 15 000 portraits classiques r√©alis√©s entre le 14e et 20e si√®cle. L‚Äôalgorithme devait donc produire un tableau en sortie qui serait tr√®s ressemblant aux portraits classiques. Nous avons d√©cid√© de comparer le portrait d‚ÄôEdmond de Belamy √† une ≈ìuvre du Louvre se trouvant dans la salle 846 de l‚Äôaile Richelieu du mus√©e. C‚Äôest une peinture datant du 17e si√®cle r√©alis√©e par Jean Bray, peintre n√©erlandais. Les tableaux ont quelques points en commun : le fond noir, un homme au centre du tableau, le col blanc avec une veste noir.\n\nPortrait de BelamyPortrait de Jean de Bray\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPortrait d‚Äôhomme, 1658\n\n\n\n\n\nLes visiteurs √©taient agr√©ablement surpris par le r√©alisme du portrait d‚ÄôEdmond de Belamy, mais aussi par le prix de vente de l‚Äô≈ìuvre. Ils pensaient pouvoir reconna√Ætre la r√©alisation d‚Äôune IA."
  },
  {
    "objectID": "projets/but_sd.html",
    "href": "projets/but_sd.html",
    "title": "Projets BUT SD",
    "section": "",
    "text": "Int√©gration de donn√©es dans un data warehouse\n\n\n1 min\n\n\n\nSQL\n\n\nBase de donn√©es\n\n\n\nConstruction d‚Äôune moyen de stockage de donn√©es et d‚Äôun dashboard pour une entreprise de e-commerce.\n\n\n\nJan 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNocturne au mus√©e du Louvre\n\n\n4 min\n\n\n\nIA\n\n\n\n\n\n\n\nNov 24, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#formation",
    "href": "about.html#formation",
    "title": "√Ä propos",
    "section": "",
    "text": "IUT de Paris - Rives de Seine (Universit√© Paris Cit√©) | Paris, France\n\n\n\nBachelor universitaire de technologie en Science des donn√©es | Sept 2022 - Juin 2025\nCours suivis : Alg√®bre, Statistique, Probabilit√©s, Programmation, Base de donn√©es, √âconomie"
  },
  {
    "objectID": "about.html#exp√©rience",
    "href": "about.html#exp√©rience",
    "title": "√Ä propos",
    "section": "Exp√©rience",
    "text": "Exp√©rience\n\n\n\n\n\n\nInstitut national de la statistique et des √©tudes √©conomiques (INSEE) | Montrouge, France\n\n\n\nProgrammeur Statistique | 2023 - 2025 Au sein de la Direction des statistiques d√©mographiques et sociales, j‚Äôai men√© des travaux d‚Äôappariement de donn√©es administratives. L‚Äôobjectif de ces travaux √©tait de mesurer et de comparer la couverture de deux bases de sondages. Par ailleurs, j‚Äôai compar√© diff√©rents algorithmes d‚Äôappariement √† l‚Äôaide d‚Äôanalyses statistiques.\nMes missions ont inclus la manipulation de donn√©es brutes, le nettoyage des donn√©es, l‚Äôappariement de grands volumes de donn√©es, ainsi que leur analyse statistique."
  },
  {
    "objectID": "about.html#comp√©tences",
    "href": "about.html#comp√©tences",
    "title": "√Ä propos",
    "section": "Comp√©tences",
    "text": "Comp√©tences\n\n\n\n\n\n\nProgrammation\n\n\n\nPython | R | SQL | SAS | GIT\n\n\n\n\n\n\n\n\nLangue\n\n\n\nAnglais (B2) | Espagnol (B2) | Arabe (C2)"
  },
  {
    "objectID": "projets/pratiquer.html",
    "href": "projets/pratiquer.html",
    "title": "PratiqueR",
    "section": "",
    "text": "J‚Äôai cr√©er PratiqueR pour les raisons suivantes :\n- Expliquer les bases du langage R de mani√®re claire et progressive.\n- Illustrer des cas d‚Äôutilisation courants √† l‚Äôaide d‚Äôexemples concrets et applicables.\n- Proposer des exercices pratiques pour renforcer vos comp√©tences et faciliter la prise en main."
  },
  {
    "objectID": "projets/projets_but/integration.html",
    "href": "projets/projets_but/integration.html",
    "title": "Int√©gration de donn√©es dans un data warehouse",
    "section": "",
    "text": "Ce projet a √©t√© r√©alis√© dans le cadre du cours d‚Äôint√©gration de donn√©es en BUT SD (2 √®me ann√©e).\nL‚Äôobjectif de ce module √©tait de nous initier au stockage de donn√©es en entreprise afin de permettre une approche d√©cisionnelle. Nous avons vu des notions telles que le data warehouse, l‚ÄôETL, les syst√®mes d‚Äôinformation d√©cisionnels, SQL‚Ä¶"
  },
  {
    "objectID": "projets/projets_but/integration.html#introduction",
    "href": "projets/projets_but/integration.html#introduction",
    "title": "Int√©gration de donn√©es dans un data warehouse",
    "section": "Introduction",
    "text": "Introduction\nUne entreprise fran√ßaise de e-commerce nous a sollicit√©s pour analyser le comportement des utilisateurs sur sa plateforme. Dans un premier temps, nous avons √©quip√© l‚Äôentreprise d‚Äôun syst√®me de stockage de donn√©es. Ensuite, nous avons mis en place un tableau de bord permettant de r√©pondre √† la probl√©matique pos√©e."
  },
  {
    "objectID": "projets/projets_but/integration.html#mod√®le-relationnel",
    "href": "projets/projets_but/integration.html#mod√®le-relationnel",
    "title": "Int√©gration de donn√©es dans un data warehouse",
    "section": "Mod√®le relationnel",
    "text": "Mod√®le relationnel\nApr√®s une √©tude approfondie de l‚Äôenvironnement et des besoins de l‚Äôentreprise, nous avons √©tabli un mod√®le relationnel pertinent, adapt√© √† l‚Äôanalyse du comportement des utilisateurs sur la plateforme.\nNous avons choisi d‚Äôutiliser un mod√®le relationnel en flocon."
  },
  {
    "objectID": "projets/pratiquer.html#acc√©dez-au-site",
    "href": "projets/pratiquer.html#acc√©dez-au-site",
    "title": "PratiqueR",
    "section": "Acc√©dez au site",
    "text": "Acc√©dez au site\nD√©couvrez PratiqueR ici"
  },
  {
    "objectID": "blog/knn.html#pr√©diction",
    "href": "blog/knn.html#pr√©diction",
    "title": "L‚Äôalgorithme des \\(k\\) plus proches voisins",
    "section": "3.1 Pr√©diction",
    "text": "3.1 Pr√©diction\nNous allons maintenant manipuler le jeu de donn√©es Abalone, disponible ici. Ce dernier contient des informations sur les ormeaux. Ce sont des mollusques marins qui poss√®dent une seule coquille et qui habitent principalement dans les eaux froides des c√¥tes. La valeur commerciale des ormeaux est √©troitement li√©e √† leur √¢ge, qui est le principal crit√®re utilis√© pour estimer leur prix. D√©terminez l‚Äô√¢ge des ormeaux se fait √† partir de leurs anneaux (rings). C‚Äôest une t√¢che g√©n√©ralement r√©alis√©e en laboratoire qui prend beaucoup de temps. Ainsi, notre objectif est de pr√©dire leur √¢ge (ici la taille de leurs anneaux) √† l‚Äôaide des variables physiologiques dont nous disposons.\nAfin de pouvoir r√©aliser notre pr√©diction nous importons les packages suivants.\n\n# Import library ---------------\nlibrary(kknn)\nlibrary(Metrics)\nlibrary(ggplot2)\n\n\nLe package kknn est une impl√©mentation de l‚Äôalgorithme des k plus proches voisins. Il permet notamment de pond√©rer les plus proches voisins lors de la pr√©diction.\nLe package Metrics est con√ßu pour √©valuer les performances des mod√®les pr√©dictifs en calculant diverses mesures d‚Äôerreur et de pr√©cision. Il est particuli√®rement utile pour les t√¢ches de r√©gression et de classification, car il propose un ensemble de fonctions pour mesurer l‚Äôexactitude des pr√©dictions. Nous l‚Äôutiliserons pour calculer l‚Äôerreur quadratique moyenne.\nLe package ggplot2 permet d‚Äôobtenir des visualisations graphiques plus pouss√©es.\n\nEnsuite, nous importons notre jeu de donn√©es en nommant les colonnes.\n\n# Import data ---------------\n# Nom des colonnes\ncolnames = c(\"Sex\",\"Length\",\"Diameter\",\"Height\",\"Whole_weight\",\"Shucked_weight\",\n             \"Viscera_weight\",\"Shell_weight\",\"Rings\")\n\n# Import de la table\nabalone &lt;- read.table(\"data_blog/abalone.data\", header = TRUE, sep = \",\", col.names = colnames)\n\nIl contient 4 176 observations et 9 variables. Nous supprimons la variable Sex et les observations pour qui la taille (Height) est √©gale √† 0.\n\n# Longeur du jeu de donnees\ndim(abalone)\n\n[1] 4176    9\n\n# Suppression de la variable Sex\nabalone &lt;- abalone[,-1]\n\n# Suppression des valeurs nul\nabalone &lt;- subset(abalone, Height!=0)\n\n# Aucune valeurs manquantes\nsapply(abalone, function(x) sum(is.na(x)))\n\n        Length       Diameter         Height   Whole_weight Shucked_weight \n             0              0              0              0              0 \nViscera_weight   Shell_weight          Rings \n             0              0              0 \n\n\nCi-dessous, un petit aper√ßu des donn√©es.\n\nhead(abalone, 4)\n\n  Length Diameter Height Whole_weight Shucked_weight Viscera_weight\n1   0.35    0.265  0.090       0.2255         0.0995         0.0485\n2   0.53    0.420  0.135       0.6770         0.2565         0.1415\n3   0.44    0.365  0.125       0.5160         0.2155         0.1140\n4   0.33    0.255  0.080       0.2050         0.0895         0.0395\n  Shell_weight Rings\n1        0.070     7\n2        0.210     9\n3        0.155    10\n4        0.055     7\n\n\n\n3.1.1 Analyse descriptive\nOn proc√®de √† une succinte analyse descritpive de notre jeu de donn√©es.\n\nsummary(abalone)\n\n     Length          Diameter         Height        Whole_weight   \n Min.   :0.0750   Min.   :0.055   Min.   :0.0100   Min.   :0.0020  \n 1st Qu.:0.4500   1st Qu.:0.350   1st Qu.:0.1150   1st Qu.:0.4421  \n Median :0.5450   Median :0.425   Median :0.1400   Median :0.8000  \n Mean   :0.5241   Mean   :0.408   Mean   :0.1396   Mean   :0.8291  \n 3rd Qu.:0.6150   3rd Qu.:0.480   3rd Qu.:0.1650   3rd Qu.:1.1538  \n Max.   :0.8150   Max.   :0.650   Max.   :1.1300   Max.   :2.8255  \n Shucked_weight   Viscera_weight    Shell_weight        Rings       \n Min.   :0.0010   Min.   :0.0005   Min.   :0.0015   Min.   : 1.000  \n 1st Qu.:0.1861   1st Qu.:0.0935   1st Qu.:0.1300   1st Qu.: 8.000  \n Median :0.3360   Median :0.1710   Median :0.2340   Median : 9.000  \n Mean   :0.3595   Mean   :0.1807   Mean   :0.2389   Mean   : 9.934  \n 3rd Qu.:0.5020   3rd Qu.:0.2530   3rd Qu.:0.3289   3rd Qu.:11.000  \n Max.   :1.4880   Max.   :0.7600   Max.   :1.0050   Max.   :29.000  \n\n\nOn observe ci-dessous la distribution de la variable Rings ainsi que la relation entre la longueur et la taille des ormeaux.\n\nggplot(abalone, aes(x = Rings)) +\n  geom_histogram(fill = \"blue\") +\n  labs(title = \"Distribution de Rings\", y = \"Fr√©quence\", x = \"Rings\") + \n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(abalone, aes(x = Length, y = Height)) +\n  geom_point(col = \"blue\", pch = 1) +\n  labs(title = \"Relation entre Height et Length\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n3.1.2 Pr√©dicition de la variable Rings\nComme dans la partie pr√©c√©dente, nous commen√ßons par cr√©er deux sous-√©chantillons distincts (√©chantillon d‚Äôapprentissage et echantillon de test) √† partir du jeu de donn√©es complet.\n\nN = round((80/100)*nrow(abalone)) # Calcul du nombre d'observations a s√©lectionner (80 %) \nidx1 &lt;- sample(1:nrow(abalone), size = N, replace = FALSE) # Tirage aleatoire des indices qu'on va s√©lectionner\ndataL &lt;- abalone[idx1,] # Construction du dataset d'apprentissage\ndataV &lt;- abalone[-idx1,] # Construction du dataset de test ou de validite\n\nA pr√©sent, on utilise la fonction kknn() pour mettre en oeuvre notre algorithme de pr√©diction en fixant \\(k = 3\\).\n\npred &lt;- kknn(Rings ~., dataL, dataV, k = 3, kernel = 'rectangular')\n\nCi-dessous, nous observons nos pr√©dictions en fonction de la variable Rings.\n\nplot(dataV$Rings,pred$fitted.values, xlab = \"Rings\", ylab = \"Prediction\", col = \"blue\")\nabline(0,1, col = \"red\")\n\n\n\n\n\n\n\n\nContrairement √† la classification, nous utiliserons l‚Äôerreur quadratique moyenne pour mesurer la performance de notre mod√®le sur l‚Äô√©chantillon de test.\n\nmse &lt;- mse(pred$fitted.values, dataV$Rings)\npaste0(\"Erreur quadratique moyenne = \",mse)\n\n[1] \"Erreur quadratique moyenne = 5.73666001330672\"\n\n\nEnfin, nous allons identifier la valeur de \\(k\\) pour laquelle l‚Äôerreur quadratique moyenne est la plus faible. On pourra alors d√©terminer le niveau optimal de \\(k\\) afin d‚Äôam√©liorer la pr√©cision du mod√®le. La boucle suivante permet de calculer l‚Äôerreur quadratique moyenne pour chaque valeur de \\(k\\) sur notre √©chantillon.\n\nkvec &lt;- 1:100\nerror &lt;- rep(NA, length(kvec))\n\nfor(i in 1:length(kvec)){\n  pred &lt;- kknn(Rings ~., dataL, dataV, k = i, kernel = 'rectangular')\n  error[i] &lt;- mse(dataV$Rings, pred$fitted.values)\n}\n\nOn visualise les r√©sultats sur le graphique ci-dessous.\n\nplot(kvec, error, type = \"b\", col = \"orange\")\nmin_error_niveau &lt;- which.min(error)\nabline(v = kvec[min_error_niveau], col = \"red\", lty = 2)\nlegend(\"topright\", legend = paste(\"Min error at k =\", kvec[min_error_niveau]), col = \"red\", lty = 2)"
  },
  {
    "objectID": "blog/knn.html#analyse-descriptive",
    "href": "blog/knn.html#analyse-descriptive",
    "title": "L‚Äôalgorithme des \\(k\\) plus proches voisins",
    "section": "4.1 Analyse descriptive",
    "text": "4.1 Analyse descriptive\nOn proc√®de √† une succinte analyse descritpive de notre jeu de donn√©es.\n\nsummary(abalone)\n\n     Length          Diameter         Height        Whole_weight   \n Min.   :0.0750   Min.   :0.055   Min.   :0.0100   Min.   :0.0020  \n 1st Qu.:0.4500   1st Qu.:0.350   1st Qu.:0.1150   1st Qu.:0.4421  \n Median :0.5450   Median :0.425   Median :0.1400   Median :0.8000  \n Mean   :0.5241   Mean   :0.408   Mean   :0.1396   Mean   :0.8291  \n 3rd Qu.:0.6150   3rd Qu.:0.480   3rd Qu.:0.1650   3rd Qu.:1.1538  \n Max.   :0.8150   Max.   :0.650   Max.   :1.1300   Max.   :2.8255  \n Shucked_weight   Viscera_weight    Shell_weight        Rings       \n Min.   :0.0010   Min.   :0.0005   Min.   :0.0015   Min.   : 1.000  \n 1st Qu.:0.1861   1st Qu.:0.0935   1st Qu.:0.1300   1st Qu.: 8.000  \n Median :0.3360   Median :0.1710   Median :0.2340   Median : 9.000  \n Mean   :0.3595   Mean   :0.1807   Mean   :0.2389   Mean   : 9.934  \n 3rd Qu.:0.5020   3rd Qu.:0.2530   3rd Qu.:0.3289   3rd Qu.:11.000  \n Max.   :1.4880   Max.   :0.7600   Max.   :1.0050   Max.   :29.000  \n\n\nOn observe ci-dessous la distribution de la variable Rings ainsi que la relation entre la longueur et la taille des ormeaux.\n\nggplot(abalone, aes(x = Rings)) +\n  geom_histogram(fill = \"blue\") +\n  labs(title = \"Distribution de Rings\", y = \"Fr√©quence\", x = \"Rings\") + \n  theme_minimal()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nggplot(abalone, aes(x = Length, y = Height)) +\n  geom_point(col = \"blue\", pch = 1) +\n  labs(title = \"Relation entre Height et Length\") +\n  theme_minimal()"
  },
  {
    "objectID": "blog/knn.html#pr√©dicition-de-la-variable-rings",
    "href": "blog/knn.html#pr√©dicition-de-la-variable-rings",
    "title": "L‚Äôalgorithme des \\(k\\) plus proches voisins",
    "section": "4.2 Pr√©dicition de la variable Rings",
    "text": "4.2 Pr√©dicition de la variable Rings\nComme dans la partie pr√©c√©dente, nous commen√ßons par cr√©er deux sous-√©chantillons distincts (√©chantillon d‚Äôapprentissage et echantillon de test) √† partir du jeu de donn√©es complet.\n\nN = round((80/100)*nrow(abalone)) # Calcul du nombre d'observations a s√©lectionner (80 %) \nidx1 &lt;- sample(1:nrow(abalone), size = N, replace = FALSE) # Tirage aleatoire des indices qu'on va s√©lectionner\ndataL &lt;- abalone[idx1,] # Construction du dataset d'apprentissage\ndataV &lt;- abalone[-idx1,] # Construction du dataset de test ou de validite\n\nA pr√©sent, on utilise la fonction kknn() pour mettre en oeuvre notre algorithme de pr√©diction en fixant \\(k = 3\\).\n\npred &lt;- kknn(Rings ~., dataL, dataV, k = 3, kernel = 'rectangular')\n\nCi-dessous, nous observons nos pr√©dictions en fonction de la variable Rings.\n\nplot(dataV$Rings,pred$fitted.values, xlab = \"Rings\", ylab = \"Prediction\", col = \"blue\")\nabline(0,1, col = \"red\")\n\n\n\n\n\n\n\n\nContrairement √† la classification, nous utiliserons l‚Äôerreur quadratique moyenne pour mesurer la performance de notre mod√®le sur l‚Äô√©chantillon de test.\n\nmse &lt;- mse(pred$fitted.values, dataV$Rings)\npaste0(\"Erreur quadratique moyenne = \",mse)\n\n[1] \"Erreur quadratique moyenne = 6.17737857618097\"\n\n\nEnfin, nous allons identifier la valeur de \\(k\\) pour laquelle l‚Äôerreur quadratique moyenne est la plus faible. On pourra alors d√©terminer le niveau optimal de \\(k\\) afin d‚Äôam√©liorer la pr√©cision du mod√®le. La boucle suivante permet de calculer l‚Äôerreur quadratique moyenne pour chaque valeur de \\(k\\) sur notre √©chantillon.\n\nkvec &lt;- 1:100\nerror &lt;- rep(NA, length(kvec))\n\nfor(i in 1:length(kvec)){\n  pred &lt;- kknn(Rings ~., dataL, dataV, k = i, kernel = 'rectangular')\n  error[i] &lt;- mse(dataV$Rings, pred$fitted.values)\n}\n\nOn visualise les r√©sultats sur le graphique ci-dessous.\n\nplot(kvec, error, type = \"b\", col = \"orange\")\nmin_error_niveau &lt;- which.min(error)\nabline(v = kvec[min_error_niveau], col = \"red\", lty = 2)\nlegend(\"topright\", legend = paste(\"Erreur min √† k =\", kvec[min_error_niveau]), col = \"red\", lty = 2)"
  },
  {
    "objectID": "projets/pratiquer.html#apprendre-r-pas-√†-pas",
    "href": "projets/pratiquer.html#apprendre-r-pas-√†-pas",
    "title": "PratiqueR",
    "section": "",
    "text": "J‚Äôai cr√©er PratiqueR pour les raisons suivantes :\n- Expliquer les bases du langage R de mani√®re claire et progressive.\n- Illustrer des cas d‚Äôutilisation courants √† l‚Äôaide d‚Äôexemples concrets et applicables.\n- Proposer des exercices pratiques pour renforcer vos comp√©tences et faciliter la prise en main."
  },
  {
    "objectID": "projets/pratiquer.html#aper√ßu-du-site",
    "href": "projets/pratiquer.html#aper√ßu-du-site",
    "title": "PratiqueR",
    "section": "Aper√ßu du site",
    "text": "Aper√ßu du site"
  }
]