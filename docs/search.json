[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rachid SAHLI",
    "section": "",
    "text": "Je suis Ã©tudiant Ã  lâ€™IUT Paris Rives de Seine en Science des donnÃ©es et alternant Ã  lâ€™INSEE. Au sein de la direction des statistiques dÃ©mographiques et sociales, mes missions portent sur la couverture de diffÃ©rentes bases de sondage et sur lâ€™appariement de gros volumes de donnÃ©es.\nJâ€™aime les statistiques, le soleil â˜€ï¸, le vÃ©lo ğŸš² , le cinÃ©ma ğŸï¸ et la programmation ğŸ‘¾."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Lâ€™algorithme des \\(k\\) plus proches voisins\n\n\n\n\n\n\nR\n\n\nMachine learning\n\n\n\nApplication sur R de lâ€™algorithme des \\(k\\) plus proches voisins.\n\n\n\n\n\n29 sept. 2024\n\n\n\n\n\n\nAucun article correspondant"
  },
  {
    "objectID": "blog/knn.html",
    "href": "blog/knn.html",
    "title": "Lâ€™algorithme des \\(k\\) plus proches voisins",
    "section": "",
    "text": "1 Introduction\nLe but de lâ€™apprentissage supervisÃ© est de prÃ©voir lâ€™Ã©tiquette (classification) \\(Y\\) ou la valeur de \\(Y\\) (rÃ©gression) associÃ©e Ã  une nouvelle entrÃ©e \\(X\\), oÃ¹ il est sous-entendu que (\\(X,Y\\)) est une nouvelle rÃ©alisation des donnÃ©es, indÃ©pendante de lâ€™Ã©chantillon observÃ©.\nLâ€™algorithme des \\(k\\) plus proches voisins est une mÃ©thode dâ€™apprentissage supervisÃ©. On peut lâ€™utiliser pour classifier quand \\(Y_i\\) est une variable qualitative, les \\(Y_i\\) sont appelÃ©s Ã©tiquettes. On peut Ã©galement lâ€™utiliser pour prÃ©dire si \\(Y_i \\in \\mathbb{R}\\). Câ€™est donc une rÃ©gression et les \\(Y_i\\) sont appelÃ©s variables Ã  expliquer.\nRemarque : On parle dâ€™apprentissage supervisÃ© car pour chaque \\(X_i\\) de lâ€™Ã©chantillon dâ€™apprentissage on dispose de \\(Y_i\\), lâ€™Ã©tiquette. Au contraire, on parlera dâ€™apprentissage non-supervisÃ© lorsque lâ€™Ã©chantillon est simplement constituÃ© des \\(X_i\\).\n\n\n2 Comment Ã§a marche ?\nEn Classification, pour un nouveau \\(X\\) on classifie son Ã©tiquette \\(Y\\) par la mÃ©thode des k-plus proches voisins de la faÃ§on suivante. On dÃ©termine tout dâ€™abord les \\(k\\) plus proches \\(X_i\\) de lâ€™Ã©chantillon par rapport Ã  \\(X\\) et on attribue la modalitÃ© dominante parmi les k modalitÃ©s observÃ©es (on parle de vote majoritaire).\nEn RÃ©gression, pour un nouveau \\(X\\) on prÃ©dit la valeur \\(Y\\) par la mÃ©thode des k-plus proches voisins de la faÃ§on suivante. On dÃ©termine tout dâ€™abord les \\(k\\) plus proches \\(X_i\\) de lâ€™Ã©chantillon par rapport Ã  \\(X\\) et on calcule la moyenne des \\(Y_i\\).\nRemarque : Pour dÃ©terminer les \\(k\\) plus proches \\(X_i\\) de \\(X\\) on utilise gÃ©nÃ©ralement la distance euclidienne. Il est possible de pondÃ©rer diffÃ©rement certaines composantes de \\(X_i\\) pour lesquelles on veut attribuer plus ou moins dâ€™importance.\nNous allons mettre en pratique ces deux mÃ©thodes Ã  travers deux exemples."
  },
  {
    "objectID": "projets.html",
    "href": "projets.html",
    "title": "Projets",
    "section": "",
    "text": "Aucun article correspondant"
  }
]